{"title":"Linear Regression","markdown":{"yaml":{"title":"Linear Regression"},"headingText":"Load a specific dataset","containsRefs":false,"markdown":"\n\n\n\n\nThis notebook will introduce you to one of the most-used machine learning packages: sklearn. We will start easy with an example very familiar to us all: OLS.\n\nAs always, start with our packages to import. The new one will be sklearn.\n\n![15.png](attachment:15.png)\n\n\n\nIn the imports above, we imported sub-packages of the sklearn package. Rather than loading the whole sklearn library (which is huge), line 4 just imports datasets and linear_model.\n\n\nNext, we will use the imported datasets object. It defines a useful function load_diabetes(). This will return a dataset object which contains the data and metadata.\n\n### Inspect the dataset object to learn about it\n\nIt's overwhelming and hard to read what is printed out, but let's dig into this notation because it's frequently used and will help us understand different Python\ndatatypes.\n\nFirst, notice that the object starts with {, which means we can treat it like a python dicitonary. Dictionaries are standard ways of expressing key-value pairs. The standard notation for a dictionary is {key1: value1, key2: value2}\n\nBelow, we will use a method from the full_dataset object that returns just the keys. This should be easier to parse.\n\nIf we want, we can access just one entry in the dictionary using the key. A useful one is the key DESCR.\n\nPrint that out using the dictionary [] notation.\n\n### Access the data array\n\nUse the `'data'` key could also extract the data and assign it to a data_array variable for inspection. Let's also print out the `type` of the object to see what the data format is.\n\nIt's a numpy array! That means we can use any of the numpy array functions on it.\n\n## Exercise 1: \n\nPrint out the mean BMI in the dataset, the sum BMI, and the sum of the squared BMI values.\nExplain why the sum of the squared BMI is what it is. To do this, you will need to access the right parts of the data array and slice out the right column.\n\nHINT: You will need to read the DESCR to understand which column the BMI is stored in.\n\nHINT 2: To create a new variable with just the desired column of the array, you can use Array slicing notation like a = data_array[:, n] where the : means you want ALL rows, and the n means you want just column n.\n\nHINT 3: You may want to use data_array.sum(), data_array.mean(), and the ** exponent operator.\n\n\nFor now, we're just going to use a single variable (a single column) for simplicity. The following line extracts just the second column from the array. The colon was necessary because we access arrays using the ROW, COLUMN notation, so we sliced out all ROWS (the colon indicates all) and the second COLUMN.\n\n\n\n### Split into training and testing arrays (the manual way)\n\nNext we are going to do a very rudimentary split of the data into training and testing sets using array slice notation. The following lines assigns the last all but the last 20 lines to the TRAIN set and the remaining 20 to the test set.\n\n**Create an empty LinearRegression object.**\n\nIn the lines below, we will follow a relatively standardized process for running a model:\n\n1. Create the model object.\n2. Fit the model.\n3. Predict with the model\n\nThe basic notation for sklearn below first creates a regression model object using the `linear_model` that we imported above. This model is \"empty\" in the sense that it has no coefficients identified. Just like othertimes we've encountered objects (like numpy array objects), this object has many functions (called methods) and attributes which can be accessed by the dot operator.\n\n#### Use the fit method\n\nUse the fit method from our regression object. It takes two inputs, the independent variables (X) and dependent variables (y). \n\nBelow, we will ONLY use the training subset of the data we created above.\n\n#### Use the fitted model to predict values\n\nNow the regression_object is \"trained,\" which means we can also call it's predict() method which will take some other observations and (in the case of OLS), multiple the new observations against our trained coefficients to make a prediciton.\n\nThe predict method returned an array of numerical predictions, which we will look at.\n\n#### Look at the coefficients\n\nMore interesting might be to look at the coefficients. Once the model has been fit, it has a new attribute .coef_ which stores an array of coefficients. In this case it will only be an array of length 1 because we just have one input.\n\n\nYou might be wondering why we are looking at the coefficients as a raw array rather than at a nicely formatted regression table. The reason is in cross-validation approaches, these coefficients might just be one step towards the final model performance check on unseen data.\n\n#### Evaluating the fit\n\nWe can use sklearn's built in evaluation functions, such as for the mean squared error or other metrics.\n\n## Exercise 2.1: Machine Learning OLS Mashup.\n\nUse loops to find which TWO variables best describe the data, as measured by R-squared. This is a hilariously brute-force approach to OLS model selection, but it is similar in some senses to Machine Learning and will be relevant to the cross-validation approaches we discuss next.\n\n## Just for completeness, let's look at this the way an econometritian would\n\nSklearn doesn't report summary statistics in the classic, econometric sense because it focuses on the train, test paradigm, which is not equivilent to a model\nperformance report (which in the classic case is only reporting performance of the TRAINING data).\n\nNonetheless, Here's how I do it, using an alternative, more econometrics-focused package. You will need to conda install statsmodel if you want to uncomment this line and have it work. Note that because we're not splitting our data into training and testing, the r-squareds are not really comparable.\n\n","srcMarkdownNoYaml":"\n\n\n\n\nThis notebook will introduce you to one of the most-used machine learning packages: sklearn. We will start easy with an example very familiar to us all: OLS.\n\nAs always, start with our packages to import. The new one will be sklearn.\n\n![15.png](attachment:15.png)\n\n\n\nIn the imports above, we imported sub-packages of the sklearn package. Rather than loading the whole sklearn library (which is huge), line 4 just imports datasets and linear_model.\n\n### Load a specific dataset\n\nNext, we will use the imported datasets object. It defines a useful function load_diabetes(). This will return a dataset object which contains the data and metadata.\n\n### Inspect the dataset object to learn about it\n\nIt's overwhelming and hard to read what is printed out, but let's dig into this notation because it's frequently used and will help us understand different Python\ndatatypes.\n\nFirst, notice that the object starts with {, which means we can treat it like a python dicitonary. Dictionaries are standard ways of expressing key-value pairs. The standard notation for a dictionary is {key1: value1, key2: value2}\n\nBelow, we will use a method from the full_dataset object that returns just the keys. This should be easier to parse.\n\nIf we want, we can access just one entry in the dictionary using the key. A useful one is the key DESCR.\n\nPrint that out using the dictionary [] notation.\n\n### Access the data array\n\nUse the `'data'` key could also extract the data and assign it to a data_array variable for inspection. Let's also print out the `type` of the object to see what the data format is.\n\nIt's a numpy array! That means we can use any of the numpy array functions on it.\n\n## Exercise 1: \n\nPrint out the mean BMI in the dataset, the sum BMI, and the sum of the squared BMI values.\nExplain why the sum of the squared BMI is what it is. To do this, you will need to access the right parts of the data array and slice out the right column.\n\nHINT: You will need to read the DESCR to understand which column the BMI is stored in.\n\nHINT 2: To create a new variable with just the desired column of the array, you can use Array slicing notation like a = data_array[:, n] where the : means you want ALL rows, and the n means you want just column n.\n\nHINT 3: You may want to use data_array.sum(), data_array.mean(), and the ** exponent operator.\n\n\nFor now, we're just going to use a single variable (a single column) for simplicity. The following line extracts just the second column from the array. The colon was necessary because we access arrays using the ROW, COLUMN notation, so we sliced out all ROWS (the colon indicates all) and the second COLUMN.\n\n\n\n### Split into training and testing arrays (the manual way)\n\nNext we are going to do a very rudimentary split of the data into training and testing sets using array slice notation. The following lines assigns the last all but the last 20 lines to the TRAIN set and the remaining 20 to the test set.\n\n**Create an empty LinearRegression object.**\n\nIn the lines below, we will follow a relatively standardized process for running a model:\n\n1. Create the model object.\n2. Fit the model.\n3. Predict with the model\n\nThe basic notation for sklearn below first creates a regression model object using the `linear_model` that we imported above. This model is \"empty\" in the sense that it has no coefficients identified. Just like othertimes we've encountered objects (like numpy array objects), this object has many functions (called methods) and attributes which can be accessed by the dot operator.\n\n#### Use the fit method\n\nUse the fit method from our regression object. It takes two inputs, the independent variables (X) and dependent variables (y). \n\nBelow, we will ONLY use the training subset of the data we created above.\n\n#### Use the fitted model to predict values\n\nNow the regression_object is \"trained,\" which means we can also call it's predict() method which will take some other observations and (in the case of OLS), multiple the new observations against our trained coefficients to make a prediciton.\n\nThe predict method returned an array of numerical predictions, which we will look at.\n\n#### Look at the coefficients\n\nMore interesting might be to look at the coefficients. Once the model has been fit, it has a new attribute .coef_ which stores an array of coefficients. In this case it will only be an array of length 1 because we just have one input.\n\n\nYou might be wondering why we are looking at the coefficients as a raw array rather than at a nicely formatted regression table. The reason is in cross-validation approaches, these coefficients might just be one step towards the final model performance check on unseen data.\n\n#### Evaluating the fit\n\nWe can use sklearn's built in evaluation functions, such as for the mean squared error or other metrics.\n\n## Exercise 2.1: Machine Learning OLS Mashup.\n\nUse loops to find which TWO variables best describe the data, as measured by R-squared. This is a hilariously brute-force approach to OLS model selection, but it is similar in some senses to Machine Learning and will be relevant to the cross-validation approaches we discuss next.\n\n## Just for completeness, let's look at this the way an econometritian would\n\nSklearn doesn't report summary statistics in the classic, econometric sense because it focuses on the train, test paradigm, which is not equivilent to a model\nperformance report (which in the classic case is only reporting performance of the TRAINING data).\n\nNonetheless, Here's how I do it, using an alternative, more econometrics-focused package. You will need to conda install statsmodel if you want to uncomment this line and have it work. Note that because we're not splitting our data into training and testing, the r-squareds are not really comparable.\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"linear_regression.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.433","bibliography":["../references.bib"],"theme":"cosmo","title":"Linear Regression"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}