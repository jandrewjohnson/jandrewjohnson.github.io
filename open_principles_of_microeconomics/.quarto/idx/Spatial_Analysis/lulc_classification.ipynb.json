{"title":"Classification of Land Cover","markdown":{"yaml":{"title":"Classification of Land Cover"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\n\n\n\n\nIn this chapter we will classify data from the Sentinel-2 satellite  using a supervised classification approach which incorporates the training data represented as a vector (shapefile). Specifically, we will be using [Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes). Naive Bayes predicts the probabilities that a data point belongs to a particular class and the class with the highest probability is considered as the most likely class. The way they get these probabilities is by using Bayes’ Theorem, which describes the probability of a feature, based on prior knowledge of conditions that might be related to that feature. Naive Bayes is quite fast when compared to some other machine learning approaches (e.g., SVM can be quite computationally intensive). This isn't to say that it is the best per se; rather it is a great first step into the world of machine learning for classification and regression.\n\n## Preparing the dataset\n#### Opening the images\nOur first step is to import the relevant packages. Of note are a couple new ones, namely rasterio and shapely. These are excellent libraries that simplify working with rasters and vectors (respectively). They wrap around GDAL so you don't have to do it the hard way. They also provide some very useful helper functions, like mask and mapping, which we explicitly import below.\n\nNow we need to collect all the Sentinal-2 bands because they come as individual images one per band. Ultimately, we're going to rewrite them into a multi-band (8 bands) geotiff for later use in regression.\n\nBelow we will create a rasterio dataset object containing all bands in order to use the mask() function and extract pixel values using geospatial polygons.\n\nWe'll do this by creating a new raster dataset and saving it for future uses.\n\nOkay we've successfully written it out now let's open it back up and make sure it meets our expectations:\n\n## Exercise:\n\nLet's clip the image and take a look at it. In the starter code below, we use the .read() method to read three different bands into a single image that we will plot. We also use numpy slice notation to clip out a smaller part of the array.\n\nHOWEVER, the image won't look right on its own. You can kind of tell there is color, but it doesn't look like it should. That's because we're reading in the wrong bands (our eyes are expecting Red, Green and Blue). \n\nAs a class race, try out different combinations of bands. When you think you've got it, raise your hand. When someone gets it, or after 2 minutes, whoever has the best image wins! Hint: if you want to nail this, just look at the sentinel documentation https://gprivate.com/62co2.\n\nOkay looks good! Our raster dataset is ready!\n\n### Now our goal is to get the pixels from the raster as outlined in each shapefile. \n\nOur training data, the shapefile we've worked with, contains one main field we care about:\n+ a Classname field (String datatype)\n\nCombined with the innate location information of polygons in a Shapefile, we have all that we need to use for pairing labels with the information in our raster.\n\nHowever, in order to pair up our vector data with our raster pixels, we will need a way of co-aligning the datasets in space. \n\nWe'll do this using the rasterio mask function which takes in a dataset and a polygon and then outputs a numpy array with the pixels in the polygon.\n\nLet's run through an example:\n\nOpen up our shapefile and check its crs\n\nRemember the projections don't match! Let's use some geopandas magic to reproject all our shapefiles to lat, long.\n\nNow we want to extract the geometry of each feature in the shapefile in GeoJSON format:\n\nNow let's extract the raster values values within the polygon using the rasterio [mask() function](https://rasterio.readthedocs.io/en/latest/api/rasterio.mask.html)\n\nOkay those looks like the right dimensions for our training data. 8 bands and 6x8 pixels seems reasonable given our earlier explorations.\n\nWe'll be doing a lot of memory intensive work so let's clean up and close this dataset.\n\n### Building the Training Data for `scikit-learn`\n\nNow let's do it for all features in the shapefile and create an array `X` that has all the pixels and an array `y` that has all the training labels.\n\n#### Pairing Y with X\nNow that we have the image we want to classify (our X feature inputs), and the land cover labels (our y labeled data), let's check to make sure they match in size so we can feed them to Naive Bayes:\n\nIt all looks good! Let's explore the spectral signatures of each class now to make sure they're actually separable since all we're going by in this classification is pixel values.\n\nThey look okay but emergent wetland and subtital haline look quite similar! They're going to be difficult to differentiate.\n\nLet's make a quick helper function, this one will convert the class labels into indicies and then assign a dictionary relating the class indices and their names.\n\n## Training the Classifier\nNow that we have our X matrix of feature inputs (the spectral bands) and our y array (the labels), we can train our model.\n\nVisit [this web page to find the usage of GaussianNaiveBayes Classifier](https://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes) from `scikit-learn`.\n\nIt is that simple to train a classifier in `scikit-learn`! The hard part is often validation and interpretation.\n\n## Predicting on the image\n\nWith our Naive Bayes classifier fit, we can now proceed by trying to classify the entire image:\n\nWe're only going to open the subset of the image we viewed above because otherwise it is computationally too intensive for most users.\n\nNow we can predict for each pixel in our image:\n\nBecause our shapefile came with the labels as strings we want to convert them to a numpy array with ints using the helper function we made earlier.\n\n### Let's visualize it!\n\nFirst we'll make a colormap so we can visualize the classes, which are just encoded as integers, in more logical colors. Don't worry too much if this code is confusing! It can be a little clunky to specify colormaps for `matplotlib`.\n\nNow show the classified map next to the RGB image!\n\n### This looks pretty good!\n\nLet's generate a map of Normalized Difference Water Index (NDWI) and NDVI just to compare with out output map.\n\nNDWI is similar to NDVI but for identifying water.\n\nSubset them to our area of interest:\n\nDisplay all four maps:\n\nLooks pretty good! Areas that are high on the NDWI ratio are generally classified as water and areas high on NDVI are forest and herbaceous. It does seem like the wetland areas (e.g. the bottom right island complex) aren't being picked up so it might be worth experimenting with other algorithms!\n\nLet's take a closer look at the Duke Marine Lab and the tip of the Rachel Carson Reserve.\n\nThis actually doesn't look half bad! Land cover mapping is a complex problem and one where there are many approaches and tools for improving a map.\n\n## Testing an Unsupervised Classification Algorithm\n\nLet's also try a unsupervised classification algorithm, k-means clustering, in the scikit-learn library ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html))\n\nK-means ([wikipedia page](https://en.wikipedia.org/wiki/K-means_clustering)) aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster.\n\nWow this looks like it was better able to distinguish some areas like the wetland and submerged sand than our supervised classification approach! But supervised usually does better with some tuning, luckily there are lots of ways to think about improving our supervised method.\n\nAdapted from the wonderful tutorial series by Patrick Gray: https://github.com/patrickcgray\n\n\n","srcMarkdownNoYaml":"\n\n\n\n\n\n\n## Introduction\nIn this chapter we will classify data from the Sentinel-2 satellite  using a supervised classification approach which incorporates the training data represented as a vector (shapefile). Specifically, we will be using [Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes). Naive Bayes predicts the probabilities that a data point belongs to a particular class and the class with the highest probability is considered as the most likely class. The way they get these probabilities is by using Bayes’ Theorem, which describes the probability of a feature, based on prior knowledge of conditions that might be related to that feature. Naive Bayes is quite fast when compared to some other machine learning approaches (e.g., SVM can be quite computationally intensive). This isn't to say that it is the best per se; rather it is a great first step into the world of machine learning for classification and regression.\n\n## Preparing the dataset\n#### Opening the images\nOur first step is to import the relevant packages. Of note are a couple new ones, namely rasterio and shapely. These are excellent libraries that simplify working with rasters and vectors (respectively). They wrap around GDAL so you don't have to do it the hard way. They also provide some very useful helper functions, like mask and mapping, which we explicitly import below.\n\nNow we need to collect all the Sentinal-2 bands because they come as individual images one per band. Ultimately, we're going to rewrite them into a multi-band (8 bands) geotiff for later use in regression.\n\nBelow we will create a rasterio dataset object containing all bands in order to use the mask() function and extract pixel values using geospatial polygons.\n\nWe'll do this by creating a new raster dataset and saving it for future uses.\n\nOkay we've successfully written it out now let's open it back up and make sure it meets our expectations:\n\n## Exercise:\n\nLet's clip the image and take a look at it. In the starter code below, we use the .read() method to read three different bands into a single image that we will plot. We also use numpy slice notation to clip out a smaller part of the array.\n\nHOWEVER, the image won't look right on its own. You can kind of tell there is color, but it doesn't look like it should. That's because we're reading in the wrong bands (our eyes are expecting Red, Green and Blue). \n\nAs a class race, try out different combinations of bands. When you think you've got it, raise your hand. When someone gets it, or after 2 minutes, whoever has the best image wins! Hint: if you want to nail this, just look at the sentinel documentation https://gprivate.com/62co2.\n\nOkay looks good! Our raster dataset is ready!\n\n### Now our goal is to get the pixels from the raster as outlined in each shapefile. \n\nOur training data, the shapefile we've worked with, contains one main field we care about:\n+ a Classname field (String datatype)\n\nCombined with the innate location information of polygons in a Shapefile, we have all that we need to use for pairing labels with the information in our raster.\n\nHowever, in order to pair up our vector data with our raster pixels, we will need a way of co-aligning the datasets in space. \n\nWe'll do this using the rasterio mask function which takes in a dataset and a polygon and then outputs a numpy array with the pixels in the polygon.\n\nLet's run through an example:\n\nOpen up our shapefile and check its crs\n\nRemember the projections don't match! Let's use some geopandas magic to reproject all our shapefiles to lat, long.\n\nNow we want to extract the geometry of each feature in the shapefile in GeoJSON format:\n\nNow let's extract the raster values values within the polygon using the rasterio [mask() function](https://rasterio.readthedocs.io/en/latest/api/rasterio.mask.html)\n\nOkay those looks like the right dimensions for our training data. 8 bands and 6x8 pixels seems reasonable given our earlier explorations.\n\nWe'll be doing a lot of memory intensive work so let's clean up and close this dataset.\n\n### Building the Training Data for `scikit-learn`\n\nNow let's do it for all features in the shapefile and create an array `X` that has all the pixels and an array `y` that has all the training labels.\n\n#### Pairing Y with X\nNow that we have the image we want to classify (our X feature inputs), and the land cover labels (our y labeled data), let's check to make sure they match in size so we can feed them to Naive Bayes:\n\nIt all looks good! Let's explore the spectral signatures of each class now to make sure they're actually separable since all we're going by in this classification is pixel values.\n\nThey look okay but emergent wetland and subtital haline look quite similar! They're going to be difficult to differentiate.\n\nLet's make a quick helper function, this one will convert the class labels into indicies and then assign a dictionary relating the class indices and their names.\n\n## Training the Classifier\nNow that we have our X matrix of feature inputs (the spectral bands) and our y array (the labels), we can train our model.\n\nVisit [this web page to find the usage of GaussianNaiveBayes Classifier](https://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes) from `scikit-learn`.\n\nIt is that simple to train a classifier in `scikit-learn`! The hard part is often validation and interpretation.\n\n## Predicting on the image\n\nWith our Naive Bayes classifier fit, we can now proceed by trying to classify the entire image:\n\nWe're only going to open the subset of the image we viewed above because otherwise it is computationally too intensive for most users.\n\nNow we can predict for each pixel in our image:\n\nBecause our shapefile came with the labels as strings we want to convert them to a numpy array with ints using the helper function we made earlier.\n\n### Let's visualize it!\n\nFirst we'll make a colormap so we can visualize the classes, which are just encoded as integers, in more logical colors. Don't worry too much if this code is confusing! It can be a little clunky to specify colormaps for `matplotlib`.\n\nNow show the classified map next to the RGB image!\n\n### This looks pretty good!\n\nLet's generate a map of Normalized Difference Water Index (NDWI) and NDVI just to compare with out output map.\n\nNDWI is similar to NDVI but for identifying water.\n\nSubset them to our area of interest:\n\nDisplay all four maps:\n\nLooks pretty good! Areas that are high on the NDWI ratio are generally classified as water and areas high on NDVI are forest and herbaceous. It does seem like the wetland areas (e.g. the bottom right island complex) aren't being picked up so it might be worth experimenting with other algorithms!\n\nLet's take a closer look at the Duke Marine Lab and the tip of the Rachel Carson Reserve.\n\nThis actually doesn't look half bad! Land cover mapping is a complex problem and one where there are many approaches and tools for improving a map.\n\n## Testing an Unsupervised Classification Algorithm\n\nLet's also try a unsupervised classification algorithm, k-means clustering, in the scikit-learn library ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html))\n\nK-means ([wikipedia page](https://en.wikipedia.org/wiki/K-means_clustering)) aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster.\n\nWow this looks like it was better able to distinguish some areas like the wetland and submerged sand than our supervised classification approach! But supervised usually does better with some tuning, luckily there are lots of ways to think about improving our supervised method.\n\nAdapted from the wonderful tutorial series by Patrick Gray: https://github.com/patrickcgray\n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"lulc_classification.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.433","bibliography":["../references.bib"],"theme":"cosmo","title":"Classification of Land Cover"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}